{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import plotly.figure_factory as ff"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "461763ebd09631f2",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df=pd.read_csv('Combined Data.csv')\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b1c14d0c305e3194",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df.info()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "add90ee67b9cb862",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df.shape"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "910b8b118c09f43f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df[df['statement']==' ']"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "76018a30dac8c9d7",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df[df['status']==' ']"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9a668b403bcc7798",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ea555f728013974a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df[df.duplicated()]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "869daa722e96f2c6",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df.fillna('',inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dd7903344bd66a6b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2d5b019eb15b5f58",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df.drop(columns=['Unnamed: 0'],inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2a1a4f8181634cea",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df.sample(5)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d45714e4a8b8f3f8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df[df['statement'].str.strip()==' ']"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8a24c5dad1395d36",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df['cleaned_comment']=df['statement'].str.lower()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "baa1269b6910b69f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "url = r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F] [0-9a-fA-F]))+'\n",
    "comment_with_url=df[df['cleaned_comment'].str.contains(url,regex=True)]\n",
    "comment_with_url"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a3e873fdc22f13dc",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df['cleaned_comment'].replace(url,' ',regex=True,inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d982cc542c19a184",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df['statement'][4786]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d80c0804eb6ce6b9",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df['cleaned_comment'][4786]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "de76b92df2525295",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df[df['cleaned_comment'].str.contains('\\n')]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f0ebe38bc10be600",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df['cleaned_comment'].replace('\\n',' ',regex=True,inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4facbeb17f71efbe",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df[df['cleaned_comment'].str.contains('\\n')]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "653f4e190aa6f675",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df['cleaned_comment'][223]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d3c971e71a414359",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    if not isinstance(text, str):  # Ensure input is a string\n",
    "        return \"\"\n",
    "\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    \n",
    "    # Fix: Remove URLs (http, https, www)\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
    "    \n",
    "    # Fix: Remove HTML tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    \n",
    "    # Fix: Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "    # Fix: Remove newlines properly\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "\n",
    "    # Fix: Remove words containing numbers\n",
    "    text = re.sub(r'\\b\\w*\\d\\w*\\b', '', text)\n",
    "    \n",
    "    # Remove extra spaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "# Test with a sample\n",
    "sample_text = \"Visit https://example.com! New product <b>50% off</b>. Call now: 123-456-7890.\"\n",
    "print(preprocess_text(sample_text))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "514b419d11ec8a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df['cleaned_comment']=df['cleaned_comment'].apply(lambda x: preprocess_text(x))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cd2cc64ca712c937",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df['cleaned_comment'][822]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ebf4ce4f7756b8fa",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,7))\n",
    "sns.countplot(data=df,x='status')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "99626aea4701d7a1",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df['word_count']=df['cleaned_comment'].apply(lambda x: len(x.split()))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e1daedc95a24fbf7",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "sns.displot(data=df, x='word_count', hue='status', kind='kde', fill=True, palette='viridis')\n",
    "plt.title('Distribution of Word Count by Status', fontsize=16)\n",
    "plt.xlabel('Word Count', fontsize=12)\n",
    "plt.ylabel('Density', fontsize=12)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ca74dcab472600ae",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "nltk.download('stopwords')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f89a702e40d43f36",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "stop_words=set(stopwords.words('english'))\n",
    "\n",
    "#  create a new column 'num_stop_words' by counting the number of stopwords in each comment\n",
    "df['num_stop_words']=df['cleaned_comment'].apply(lambda x: len([word for word in x.split() if word in stop_words]))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d84a69b9a4ac7d40",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# create a distribution plot of 'num_stop_words' column\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "sns.histplot(df['num_stop_words'],kde=True)\n",
    "plt.title('distribution of stop words')\n",
    "plt.xlabel('number of stop words')\n",
    "plt.ylabel('frequency')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "46f3438ecb176e01",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(data=df,x='status',y='num_stop_words',estimator=np.median)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b94b2a07dbe6282e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# extract all stopwords from clean_comment column\n",
    "all_stop_words=[word for comment in df['cleaned_comment'] for word in comment.split() if word in stop_words]\n",
    "\n",
    "# count the frequency of each stopword\n",
    "most_common_stop_words=Counter(all_stop_words).most_common(25)\n",
    "\n",
    "top_25_df=pd.DataFrame(most_common_stop_words,columns=['stopword','count'])\n",
    "top_25_df.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "353bae402b9ae1c8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "sns.barplot(data=top_25_df,y='stopword',x='count',palette='viridis')\n",
    "plt.title('top 25 most common stopwords')\n",
    "plt.xlabel('count')\n",
    "plt.ylabel('stopword')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3c124b00e90b3556",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_word_count(text):\n",
    "  wordcloud=WordCloud(width=800,height=400,background_color='white').generate(' '.join(text))\n",
    "  plt.figure(figsize=(10,5))\n",
    "  plt.imshow(wordcloud,interpolation='bilinear')\n",
    "  plt.axis('off')\n",
    "  plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e16b57d0113ae813",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plot_word_count(df['cleaned_comment'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c9db66357f4f8da0",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "x=df['cleaned_comment']\n",
    "y=df['status']"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e3c023d372c54253",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=42,test_size=0.2)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f59f94c7e4dec1ef",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "vectorizer=TfidfVectorizer()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "96d7584988880204",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "x_train_tfidf = vectorizer.fit_transform(x_train)\n",
    "x_test_tfidf = vectorizer.transform(x_test)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e3a39804258df232",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "lr=LogisticRegression()\n",
    "mnb=MultinomialNB()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4cfa321fc74b89a8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "lr.fit(x_train_tfidf,y_train)\n",
    "y_pred=lr.predict(x_test_tfidf)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ea59c7d485141861",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9c4d67644965ad49",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm_fig = ff.create_annotated_heatmap(\n",
    "    z=cm,\n",
    "    x=list(set(y_test)),\n",
    "    y=list(set(y_test)),\n",
    "    annotation_text=cm,\n",
    "    colorscale='Viridis'\n",
    ")\n",
    "cm_fig.update_layout(title='Confusion Matrix')\n",
    "cm_fig.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "96cc24c720f513d1",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "accuracy_score(y_test,y_pred)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "debd97d7eb8c3db3",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "mnb.fit(x_train_tfidf,y_train)\n",
    "y_pred=mnb.predict(x_test_tfidf)\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm_fig = ff.create_annotated_heatmap(\n",
    "    z=cm,\n",
    "    x=list(set(y_test)),\n",
    "    y=list(set(y_test)),\n",
    "    annotation_text=cm,\n",
    "    colorscale='Viridis'\n",
    ")\n",
    "cm_fig.update_layout(title='Confusion Matrix')\n",
    "cm_fig.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3a9918fb27a7aa81",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "accuracy_score(y_test,y_pred)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "684711c84101af85",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "dt=DecisionTreeClassifier()\n",
    "dt.fit(x_train_tfidf,y_train)\n",
    "y_pred=dt.predict(x_test_tfidf)\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm_fig = ff.create_annotated_heatmap(\n",
    "    z=cm,\n",
    "    x=list(set(y_test)),\n",
    "    y=list(set(y_test)),\n",
    "    annotation_text=cm,\n",
    "    colorscale='Viridis'\n",
    ")\n",
    "cm_fig.update_layout(title='Confusion Matrix')\n",
    "cm_fig.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "993f4048b1631a6d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "accuracy_score(y_test,y_pred)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dcb2e165fcd9236e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# rf=RandomForestClassifier()\n",
    "# rf.fit(x_train_tfidf,y_train)\n",
    "# y_pred=rf.predict(x_test_tfidf)\n",
    "# # Confusion Matrix\n",
    "# cm = confusion_matrix(y_test, y_pred)\n",
    "# cm_fig = ff.create_annotated_heatmap(\n",
    "#     z=cm,\n",
    "#     x=list(set(y_test)),\n",
    "#     y=list(set(y_test)),\n",
    "#     annotation_text=cm,\n",
    "#     colorscale='Viridis'\n",
    "# )\n",
    "# cm_fig.update_layout(title='Confusion Matrix')\n",
    "# cm_fig.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a670a58fceac09ed",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# accuracy_score(y_test,y_pred)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "28e18cdd8bdc5626",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Install required libraries for BERT\n",
    "# !pip install transformers torch\n",
    "\n",
    "# Import necessary libraries for BERT\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import plotly.figure_factory as ff"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "24c053f891f38728",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Ensure device is set (GPU if available, else CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Step 1: Prepare the data for BERT\n",
    "# Since BERT requires tokenized input, we use BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Encode the labels (status) into numerical values\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "num_labels = len(label_encoder.classes_)\n",
    "\n",
    "# Split the data again (same split as before for consistency)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y_encoded, random_state=42, test_size=0.2)\n",
    "\n",
    "# Tokenize the text data for BERT\n",
    "def tokenize_data(texts, max_length=128):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    for text in texts:\n",
    "        encoded = tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,  # Add [CLS] and [SEP]\n",
    "            max_length=max_length,    # Maximum length for BERT input\n",
    "            padding='max_length',     # Pad to max_length\n",
    "            truncation=True,          # Truncate longer texts\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'       # Return PyTorch tensors\n",
    "        )\n",
    "        input_ids.append(encoded['input_ids'])\n",
    "        attention_masks.append(encoded['attention_mask'])\n",
    "    return torch.cat(input_ids, dim=0), torch.cat(attention_masks, dim=0)\n",
    "\n",
    "# Tokenize training and testing data\n",
    "x_train_ids, x_train_masks = tokenize_data(x_train)\n",
    "x_test_ids, x_test_masks = tokenize_data(x_test)\n",
    "\n",
    "# Convert labels to tensors\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# Create TensorDatasets and DataLoaders for batch processing\n",
    "train_dataset = TensorDataset(x_train_ids, x_train_masks, y_train_tensor)\n",
    "test_dataset = TensorDataset(x_test_ids, x_test_masks, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# Step 2: Load pre-trained BERT model\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    'bert-base-uncased',\n",
    "    num_labels=num_labels,  # Number of unique labels\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "# Step 3: Set up optimizer and training parameters\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-8)\n",
    "epochs = 3\n",
    "\n",
    "# Step 4: Fine-tune BERT\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        input_ids, attention_mask, labels = [b.to(device) for b in batch]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Average Loss: {avg_loss:.4f}\")\n",
    "\n",
    "# Step 5: Evaluate BERT model\n",
    "model.eval()\n",
    "predictions = []\n",
    "true_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids, attention_mask, labels = [b.to(device) for b in batch]\n",
    "        \n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "        \n",
    "        predictions.extend(preds)\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Step 6: Calculate accuracy and confusion matrix\n",
    "bert_accuracy = accuracy_score(true_labels, predictions)\n",
    "print(f\"BERT Accuracy: {bert_accuracy:.4f}\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "cm_fig = ff.create_annotated_heatmap(\n",
    "    z=cm,\n",
    "    x=list(label_encoder.classes_),\n",
    "    y=list(label_encoder.classes_),\n",
    "    annotation_text=cm,\n",
    "    colorscale='Viridis'\n",
    ")\n",
    "cm_fig.update_layout(title='Confusion Matrix for BERT')\n",
    "cm_fig.show()\n",
    "\n",
    "# Optional: Compare with previous models\n",
    "print(\"Model Performance Comparison:\")\n",
    "print(f\"Logistic Regression Accuracy: {accuracy_score(y_test, lr.predict(x_test_tfidf)):.4f}\")\n",
    "print(f\"Multinomial Naive Bayes Accuracy: {accuracy_score(y_test, mnb.predict(x_test_tfidf)):.4f}\")\n",
    "print(f\"Decision Tree Accuracy: {accuracy_score(y_test, dt.predict(x_test_tfidf)):.4f}\")\n",
    "print(f\"BERT Accuracy: {bert_accuracy:.4f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "492663b116e5d3b4",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "6fbe8be54317e37a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
